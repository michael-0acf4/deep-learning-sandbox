# Deep Learning sandbox/playground.

Continuation of [my old autograd](https://github.com/michael-0acf4/auto-diff-playground). Everything else is pretty much about efficiency, hence the use of Pytorch, would probably also rewrite [word2vec](https://github.com/michael-0acf4/yw2v) in Pytorch.


To be covered (all from scratch), sorted by difficulty.

- [x] Pytorch and its autograd API
- [x] Basic stacked linear layers
- [x] CNNs
- [ ] Attention
    - [ ] Self-attention
    - [ ] Cross-attention
    - [ ] Multihead attention
    - [ ] Flash attention
- [ ] Transformers + Attention
    - [ ] Vision Transformers (side quest, might skip)
- [ ] Vanilla RNNs (might skip)
- [ ] Understanding LSTMs/GRUs
- [ ] GPT
- [ ] Diffusion models (probably the hardest)
